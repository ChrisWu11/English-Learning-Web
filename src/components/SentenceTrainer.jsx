import { useMemo, useState } from 'react';
import { useRecorder } from '../hooks/useRecorder';
import { useSpeechRecognition } from '../hooks/useSpeechRecognition';
import { similarityScore } from '../utils/levenshtein';

function normalizeText(text = '') {
  return text
    .toLowerCase()
    .replace(/[^a-z\s]/gi, '')
    .replace(/\s+/g, ' ')
    .trim();
}

export default function SentenceTrainer({ sentence }) {
  const [note, setNote] = useState('');

  const {
    isSupported: recorderSupported,
    isRecording,
    audioURL,
    error: recorderError,
    startRecording,
    stopRecording,
    resetRecording,
  } = useRecorder();

  const {
    supported: speechSupported,
    transcript,
    error: speechError,
    isListening,
    startRecognition,
    stopRecognition,
  } = useSpeechRecognition('en-GB');

  const speechReady = useMemo(
    () => 'speechSynthesis' in window,
    []
  );

  const normalizedTranscript = useMemo(() => normalizeText(transcript), [transcript]);
  const normalizedOrigin = useMemo(() => normalizeText(sentence), [sentence]);

  const calculatedScore = useMemo(() => {
    if (!normalizedTranscript) return null;
    return similarityScore(normalizedOrigin, normalizedTranscript);
  }, [normalizedOrigin, normalizedTranscript]);

  const handleSpeak = () => {
    if (!speechReady) return;
    const utterance = new SpeechSynthesisUtterance(sentence);
    utterance.lang = 'en-GB';
    const voices = window.speechSynthesis.getVoices();
    const britishVoice = voices.find(v => v.lang === 'en-GB');
    if (britishVoice) utterance.voice = britishVoice;
    window.speechSynthesis.speak(utterance);
  };

  const handleRecordToggle = async () => {
    if (!recorderSupported || !speechSupported) {
      setNote('Your browser does not fully support the required audio APIs.');
      return;
    }

    if (isRecording) {
      stopRecording();
      stopRecognition();
      setNote('Processing your speech...');
    } else {
      resetRecording();
      setNote('Listening...');
      await startRecording();
      startRecognition();
    }
  };

  const handlePlay = () => {
    if (!audioURL) return;
    const audio = new Audio(audioURL);
    audio.play();
  };

  return (
    <div className="sentence-card">
      <div className="sentence-card__header">
        <p className="sentence-card__text">{sentence}</p>
        <div className="sentence-card__actions">
          <button className="ghost" onClick={handleSpeak} disabled={!speechReady}>
            ğŸ”ˆ è‹±å¼æœ—è¯»
          </button>
          <button
            className={isRecording ? 'danger' : 'primary'}
            onClick={handleRecordToggle}
            disabled={!recorderSupported || !speechSupported}
          >
            {isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³'}
          </button>
          <button className="outline" onClick={handlePlay} disabled={!audioURL}>
            â–¶ï¸ æ’­æ”¾å½•éŸ³
          </button>
        </div>
      </div>

      <div className="sentence-card__body">
        <div className="chip">{isListening ? 'è¯­éŸ³è¯†åˆ«ä¸­...' : 'å‡†å¤‡å¥½ç»ƒä¹ '}</div>
        {note && <div className="note">{note}</div>}
        {recorderError && <div className="error">å½•éŸ³é”™è¯¯ï¼š{recorderError}</div>}
        {speechError && <div className="error">è¯†åˆ«é”™è¯¯ï¼š{speechError}</div>}

        <div className="result">
          <div>
            <p className="label">è¯†åˆ«ç»“æœ</p>
            <p className="result__text">{transcript || 'æš‚æ— ç»“æœï¼Œè¯·å½•éŸ³'}</p>
          </div>
          <div className="score">
            <p className="label">å¾—åˆ†</p>
            <p className="score__value">{calculatedScore === null ? '--' : `${calculatedScore} / 100`}</p>
          </div>
        </div>
      </div>
    </div>
  );
}
